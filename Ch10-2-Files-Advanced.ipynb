{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Topics on Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with HTML files\n",
    "- fetch an HTML page from web\n",
    "- parse the HTML file with BeautifulSoup library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('teaching.html', <http.client.HTTPMessage at 0x7fa0c5e5cdc0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch an html page\n",
    "import urllib.request\n",
    "url = 'https://rambasnet.github.io/teaching.html'\n",
    "localfile = 'teaching.html'\n",
    "urllib.request.urlretrieve(url, localfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9653 words in the file.\n"
     ]
    }
   ],
   "source": [
    "with open(localfile) as f:\n",
    "    data = f.read()\n",
    "words = data.split(' ')\n",
    "print('There are {0} words in the file.'.format(len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parsing HTML using BeautifulSoup library\n",
    "- install Beautifulsoup library\n",
    "    $ pip install bs4\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/#\n",
    "- Alternative is nltk (Natural Language Toolkit) library\n",
    "- http://www.nltk.org/\n",
    "\n",
    "## Installing Parsers\n",
    "- supports the HTML parser included in Python’s standard library\n",
    "- also supports a number of third-party Python parsers such as very fast `lxml` parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 292 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=14cd4ba62626eff1dcc9a1ad692e42baa3a7b5c025cc58a0562bb32b998e4381\n",
      "  Stored in directory: /Users/rbasnet/Library/Caches/pip/wheels/75/78/21/68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.9.3 bs4-0.0.1 soupsieve-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# can run terminal/bash commands from notebook using !\n",
    "! pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/rbasnet/miniconda3/lib/python3.8/site-packages (4.6.1)\r\n"
     ]
    }
   ],
   "source": [
    "# install lxml parser\n",
    "! pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Ram Basnet | Homepage\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dr. Ram Basnet\n",
      "Associate Professor of Computer Science\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home\n",
      "\n",
      "\n",
      "Teaching\n",
      "\n",
      "\n",
      "Research\n",
      "\n",
      "\n",
      "Resources\n",
      "\n",
      "\n",
      "Contact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Teaching\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Teaching Interests\n",
      "\n",
      "Cybersecurity\n",
      "\n",
      "                    Python, C++, SQL and NoSQL Databases, JavaScript, NodeJS\n",
      "                \n",
      "Data Science\n",
      "\n",
      "                    Web Design and Secure Web App Development\n",
      "                \n",
      "\n",
      "\n",
      "Courses Taught at CMU\n",
      "\n",
      "                CSCI 106: Web1 - Web Page Design I\n",
      "                6\n",
      "\n",
      "\n",
      "                CSCI 110: Beg. Prog. Python & Lab\n",
      "                8\n",
      "\n",
      "\n",
      "                CSCI 111: CS1 - Foundation of CS\n",
      "                8\n",
      "\n",
      "\n",
      "                CSCI 112: CS2 - Data Structures\n",
      "                7\n",
      "\n",
      "\n",
      "                CSCI 206: Web2 - Web Page Design II\n",
      "                2\n",
      "\n",
      "\n",
      "                CSCI 250: CS3 - Intro to Algorithms\n",
      "                3\n",
      "\n",
      "\n",
      "                CSCI 310: Adv. Prog. Python\n",
      "                8\n",
      "\n",
      "\n",
      "                CSCI 310: Adv. Prog. JavaScript\n",
      "                1\n",
      "\n",
      "\n",
      "                CSCI 370: Computer Security\n",
      "                5\n",
      "\n",
      "\n",
      "                CSCI 420: Cybersecurity\n",
      "                6\n",
      "\n",
      "\n",
      "                CSCI 465: Net/App Security\n",
      "                6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FALL 2020 SCHEDULE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mon\n",
      "Tues\n",
      "Wed\n",
      "Thrs\n",
      "Fri\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10:00\n",
      "\n",
      "                                Off. Hr.CH 32110-10:50\n",
      "                            \n",
      "\n",
      "                                Adv. PythonCH 27610-10:50\n",
      "                            \n",
      "\n",
      "                                Off. Hr.CH 32110-10:50\n",
      "                            \n",
      "\n",
      "                                Adv. PythonCH 27610-10:50\n",
      "                            \n",
      "\n",
      "                                Off. Hr.CH 32110-10:50\n",
      "                            \n",
      "\n",
      "\n",
      "10:30\n",
      "\n",
      "\n",
      "11:00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "11:30\n",
      "\n",
      "\n",
      "12:00\n",
      "\n",
      "                                CS 1WS 12012-12:50\n",
      "                            \n",
      "\n",
      "                                CS 1WS 12012-12:50\n",
      "                            \n",
      "\n",
      "                                CS 1WS 12012-12:50\n",
      "                            \n",
      "\n",
      "                                CS 1WS 12012-12:50\n",
      "                            \n",
      "\n",
      "                                Off. Hr.CH 32112-12:50\n",
      "                            \n",
      "\n",
      "\n",
      "12:30\n",
      "\n",
      "\n",
      "1:00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1:30\n",
      "\n",
      "\n",
      "2:00\n",
      "\n",
      "                                Net/App SecWS 1202-2:50\n",
      "                            \n",
      "\n",
      "                                Off. Hr.CH 3212-2:50\n",
      "                            \n",
      "\n",
      "                                Net/App SecWS 1202-2:50\n",
      "                            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                Net/App SecWS 1202-2:50\n",
      "                            \n",
      "\n",
      "\n",
      "2:30\n",
      "\n",
      "\n",
      "3:00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3:30\n",
      "\n",
      "\n",
      "4:00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4:30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Home | Teaching |\n",
      "        Research  |\n",
      "        Resources |\n",
      "         Contact       ©\n",
      "        2019\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "localfile = 'teaching.html'\n",
    "with open(localfile) as f:\n",
    "    #soup = BeautifulSoup(f, 'lxml') # used to but now not working!\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "text = soup.get_text()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into lines and remove leading and trailing space on each line\n",
    "lines = [line.strip() for line in text.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', 'Ram Basnet | Homepage', '', '', '', '', '', '', '', '', '', '', '', '', 'Dr. Ram Basnet', 'Associate Professor of Computer Science', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(lines[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of words by spliting multi-word elements\n",
    "words = [word.strip().lower() for line in lines for word in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ram', 'basnet', '|', 'homepage', 'dr.', 'ram', 'basnet', 'associate', 'professor', 'of', 'computer', 'science', 'home', 'teaching', 'research', 'resources', 'contact', 'teaching', 'teaching', 'interests']\n"
     ]
    }
   ],
   "source": [
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 192 words in the file.\n"
     ]
    }
   ],
   "source": [
    "print('There are {0} words in the file.'.format(len(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find histogram of words\n",
    "- use DefaultDict found in collections module\n",
    "- https://docs.python.org/3/library/collections.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = defaultdict(int)\n",
    "for w in words:\n",
    "    hist[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 10 most common words\n",
    "listHist = [(k, v) for k, v in hist.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ram', 2), ('basnet', 2), ('|', 5), ('homepage', 1), ('dr.', 1), ('associate', 1), ('professor', 1), ('of', 2), ('computer', 2), ('science', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(listHist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "listHist.sort(key = lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('csci', 11), ('|', 5), ('-', 5), ('cs', 5), ('off.', 5), ('hr.ch', 5), ('teaching', 4), ('web', 4), ('adv.', 4), ('net/app', 4)]\n"
     ]
    }
   ],
   "source": [
    "print(listHist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Counter collection\n",
    "- easier way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('csci', 11),\n",
       " ('|', 5),\n",
       " ('-', 5),\n",
       " ('cs', 5),\n",
       " ('off.', 5),\n",
       " ('hr.ch', 5),\n",
       " ('teaching', 4),\n",
       " ('web', 4),\n",
       " ('adv.', 4),\n",
       " ('net/app', 4)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working with binary files\n",
    "- the following example copies a binary file such as image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileSrc = './resources/brain.jpg'\n",
    "fileDst = 'brain-copy.jpg'\n",
    "with open(fileSrc, 'rb') as rbf: \n",
    "    #rb - read binary mode\n",
    "    data = rbf.read() # read the whole binary file\n",
    "    with open(fileDst, 'wb') as wbf:\n",
    "        wbf.write(data) # write the whole binary file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use checksum to compare if two files match exactly!\n",
    "- checksum makes sure that not a single bit is different between the two files\n",
    "- used in security\n",
    "- import and use hashlib - https://docs.python.org/3/library/hashlib.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two files checksums match!\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "file1Contents = open(fileSrc, 'rb').read()\n",
    "file2Contents = open(fileDst, 'rb').read()\n",
    "\n",
    "file1ChkSum = hashlib.sha256(file1Contents).hexdigest()\n",
    "file2ChkSum = hashlib.sha256(file2Contents).hexdigest()\n",
    "if (file1ChkSum == file2ChkSum):\n",
    "    print('two files\\' checksums match!')\n",
    "else:\n",
    "    print('oops! two files\\' checksums do NOT match!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python object serialization with pickle library\n",
    "- https://docs.python.org/3/library/pickle.html\n",
    "- pickle module implements binary protocols for serializing and de-serializing a Python object\n",
    "- Pickling - serializing python object\n",
    "- Un-pickling - de-serializing python object (inverse operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "alist = list(range(2, 21, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n"
     ]
    }
   ],
   "source": [
    "print(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pickle alist; serialize a list\n",
    "pickleFile = 'myPickle.pkl'\n",
    "with open(pickleFile, 'wb') as p:\n",
    "    pickle.dump(alist, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets unpickle alist; deserialize a list\n",
    "with open(pickleFile, 'rb') as p:\n",
    "    blist = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist == blist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump Counter\n",
    "with open('wordCounter.pkl', 'wb') as p:\n",
    "    pickle.dump(hist, p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle\n",
    "with open('wordCounter.pkl', 'rb') as p:\n",
    "    newHist = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist == newHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('csci', 11), ('|', 5), ('-', 5)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newHist.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
